{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo\n",
    "\n",
    "\n",
    "참고 : https://github.com/deepinsight/insightface/tree/master/python-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "from PIL import Image\n",
    "\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider']) # 모델 이름을 인자로 줘서 원하는 모델 사용 가능\n",
    "app.prepare(ctx_id=0, det_size=(640, 640)) # det_size 는 face detection 후에 crop된 얼굴 크기를 얼마나의 크기로 resize할 것인지를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(path): # Input : rgb 이미지의 경로\n",
    "                     # Output : 이미지에 있는 얼굴들의 임베딩\n",
    "    img = np.asarray(Image.open(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # 이미지를 BGR 형식으로 바꿔 주어야 한다.\n",
    "    faces = app.get(img)\n",
    "    embeddings = []\n",
    "    for tmp in faces:\n",
    "        embeddings.append(tmp[\"embedding\"])\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(embed_1, embed_2): # Input : 두 그림의 embedding\n",
    "                            # Output : 두 그림 사이의 거리\n",
    "                            # 거리를 측정하는 방식들을 여러 가지로 구현해 보면서 성능 향상을 노려볼 수 있을 것 같다.\n",
    "    return np.linalg.norm(embed_1 - embed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_in_image(path_image, target_embedding, threshold = 20): # Input : rgb 이미지의 경로, 사진 속에 있는지 확인하고 싶은 사람(타겟)의 임베딩, threshold\n",
    "                                                              # Output : 이미지에 해당 사람(타겟)이 있는지 true/false\n",
    "                                                              # 적절한 threshold 값을 선택하여 성능 향상을 노려볼 수 있을 것 같다.\n",
    "    embeddings = get_embed(path_image)\n",
    "    for embedding in embeddings:\n",
    "        if(dist(embedding, target_embedding) < threshold):\n",
    "            return True # target exist in image\n",
    "    return False # target is not found in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ParkMinSu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "image_folder_path = \"images/\"\n",
    "path_list = [\"img1.jpg\", \"img2.png\", \"img3.jfif\", \"img4.jpg\"]\n",
    "\n",
    "target_image = \"target.jpg\" # 유재석의 사진\n",
    "target_embed = get_embed(image_folder_path + target_image)[0] # 유재석의 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for path in path_list:\n",
    "    print(target_in_image(image_folder_path + path, target_embed))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "020eb92898ac559bd98722b535e6235e035f297f752a3a61b26b02297b428980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
