{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8MS-IDpTyM_",
        "outputId": "3e15f4de-8807-4669-d73d-1db6e15d1e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_sc\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '0', 'cudnn_conv1d_pad_to_nc1d': '0'}, 'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\ParkMinSu/.insightface\\models\\buffalo_sc\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import insightface\n",
        "from PIL import Image\n",
        "from insightface.app import FaceAnalysis\n",
        "from insightface.data import get_image as ins_get_image\n",
        "\n",
        "app = FaceAnalysis(name = 'buffalo_sc', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "#detect하고 square patches are cropped from the origina limage and resized to 640*640\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "tsjNqXtotCNj"
      },
      "outputs": [],
      "source": [
        "def get_embed(path): # Input : rgb 이미지의 경로\n",
        "                     # Output : 이미지에 있는 얼굴들의 임베딩\n",
        "    img = np.asarray(Image.open(path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # 이미지를 BGR 형식으로 바꿔 주어야 한다.\n",
        "    faces = app.get(img)\n",
        "    embeddings = []\n",
        "    for tmp in faces:\n",
        "        embeddings.append(tmp[\"embedding\"])\n",
        "    \n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "BOQVpI_YMuB4"
      },
      "outputs": [],
      "source": [
        "def similarity(embed_1, embed_2):\n",
        "    n1 = np.linalg.norm(embed_1)\n",
        "    n2 = np.linalg.norm(embed_2)\n",
        "    return np.dot(embed_1, embed_2)/(n1*n2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "40j7TgatZFWH"
      },
      "outputs": [],
      "source": [
        "def dist(embed_1, embed_2):\n",
        "\n",
        "    return np.linalg.norm(embed_1 - embed_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "B4nDk2Mcmi2q"
      },
      "outputs": [],
      "source": [
        "def embed_list(dir_path):\n",
        "  embed_vectors=[]\n",
        "  for (root, directories, files) in os.walk(dir_path):\n",
        "    files = sorted(files)\n",
        "    print(files)\n",
        "    for file in files:\n",
        "      file_path = os.path.join(root, file)\n",
        "      print(file_path)\n",
        "      embed_vectors.append(get_embed(file_path))\n",
        "  return embed_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "fZPRs4NaMwuH"
      },
      "outputs": [],
      "source": [
        "def target_in_image(img_embeddings, target_embedding, threshold = 0.4): # Input : rgb 이미지의 경로, 사진 속에 있는지 확인하고 싶은 사람(타겟)의 임베딩, threshold\n",
        "                                                              # Output : 이미지에 해당 사람(타겟)이 있는지 true/false\n",
        "                                                              # 적절한 threshold 값을 선택하여 성능 향상을 노려볼 수 있을 것 같다.\n",
        "    for embedding in img_embeddings:\n",
        "        if(similarity(embedding, target_embedding[0]) > threshold):\n",
        "            return 1 # target exist in image\n",
        "    return 0 # target is not found in image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WBTylyOSUsm",
        "outputId": "f3f83e7c-0dbf-4b9d-d0a8-e3314974fd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.png', '1.jfif', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg']\n",
            "images/0.png\n",
            "images/1.jfif\n",
            "images/2.jpg\n",
            "images/3.jpg\n",
            "images/4.jpg\n",
            "images/5.jpg\n",
            "images/6.jpg\n",
            "images/7.jpg\n",
            "images/8.jpg\n",
            "['0.jpg', '1.jpg', '2.jpg']\n",
            "targets/0.jpg\n",
            "targets/1.jpg\n",
            "targets/2.jpg\n",
            "010000000\n",
            "000111110\n",
            "110000000\n",
            "\n",
            "010000000000111110110000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "img_embed_list = embed_list('images/')\n",
        "target_list = embed_list('targets/')\n",
        "answer_str = \"\"\n",
        "for target in target_list:\n",
        "  for img in img_embed_list:\n",
        "      a = target_in_image(img, target)\n",
        "      answer_str+=str(a)\n",
        "      print(a, end='')\n",
        "  print()\n",
        "\n",
        "print()\n",
        "print(answer_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "ZIH8yCO0SACm"
      },
      "outputs": [],
      "source": [
        "def classified_image(image_list, target_list):\n",
        "    answer_str = \"\"\n",
        "    for target in target_list:\n",
        "        target_embed = get_embed(target)\n",
        "        for img in image_list:\n",
        "            answer_str+str(target_in_image(img, target_embed))\n",
        "    return answer_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hiyg5lr6A5c7",
        "outputId": "22e56a3f-fa13-438f-b02c-3f5790bdc002"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dir_path = \"sample_data/\"\n",
        "\n",
        "for (root, directories, files) in os.walk(dir_path):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0N8Xk9RA5X4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "020eb92898ac559bd98722b535e6235e035f297f752a3a61b26b02297b428980"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
